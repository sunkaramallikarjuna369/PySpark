<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CDC Implementation - DW Learning Hub</title>
    <link rel="stylesheet" href="../../assets/css/main.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <header class="header">
        <div class="container header-content">
            <a href="../../index.html" class="logo"><span>Data Engineering Hub</span></a>
            <nav class="nav"><a href="../../index.html#datawarehouse" class="nav-link active">Data Warehouse</a><button class="theme-toggle">ðŸŒ™</button></nav>
        </div>
    </header>
    <main class="container">
        <section class="section">
            <h1>CDC Implementation</h1>
            <p>Change Data Capture (CDC) captures and delivers changes from source databases to data warehouses in real-time or near-real-time.</p>
            <div id="visualization" class="visualization-container"></div>
            <div class="visualization-controls">
                <button class="viz-btn" onclick="showCDCFlow()">CDC Flow</button>
                <button class="viz-btn" onclick="showCDCTypes()">CDC Types</button>
            </div>
            <h2>Code Examples</h2>
            <div class="tabs">
                <button class="tab active" data-tab="debezium">Debezium CDC</button>
                <button class="tab" data-tab="processing">CDC Processing</button>
                <button class="tab" data-tab="delta">Delta Lake CDC</button>
            </div>
            <div class="tab-contents">
                <div id="debezium" class="tab-content active">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">JSON</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>// Debezium CDC Event Structure
{
  "schema": {...},
  "payload": {
    "before": {
      "id": 1,
      "name": "Alice",
      "city": "New York"
    },
    "after": {
      "id": 1,
      "name": "Alice",
      "city": "Los Angeles"
    },
    "source": {
      "version": "2.0.0",
      "connector": "mysql",
      "name": "mydb",
      "ts_ms": 1704067200000,
      "db": "inventory",
      "table": "customers"
    },
    "op": "u",  // c=create, u=update, d=delete, r=read(snapshot)
    "ts_ms": 1704067200123
  }
}

// Debezium Connector Configuration (MySQL)
{
  "name": "inventory-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "mysql",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "184054",
    "database.server.name": "dbserver1",
    "database.include.list": "inventory",
    "table.include.list": "inventory.customers,inventory.orders",
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "schema-changes.inventory"
  }
}</pre>
                        </div>
                    </div>
                </div>
                <div id="processing" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_json, when, current_timestamp
from pyspark.sql.types import StructType, StructField, StringType, LongType

spark = SparkSession.builder.appName("CDCProcessing").getOrCreate()

# Define CDC event schema
cdc_schema = StructType([
    StructField("op", StringType()),  # Operation type
    StructField("before", StructType([
        StructField("id", LongType()),
        StructField("name", StringType()),
        StructField("city", StringType())
    ])),
    StructField("after", StructType([
        StructField("id", LongType()),
        StructField("name", StringType()),
        StructField("city", StringType())
    ])),
    StructField("ts_ms", LongType())
])

# Read CDC events from Kafka
cdc_stream = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "dbserver1.inventory.customers") \
    .option("startingOffsets", "earliest") \
    .load()

# Parse CDC events
parsed_cdc = cdc_stream \
    .select(from_json(col("value").cast("string"), cdc_schema).alias("cdc")) \
    .select("cdc.*")

# Process based on operation type
def process_cdc_event(df, batch_id):
    # Handle inserts (op = 'c' or 'r')
    inserts = df.filter(col("op").isin("c", "r")) \
        .select("after.*") \
        .withColumn("cdc_operation", lit("INSERT"))
    
    # Handle updates (op = 'u')
    updates = df.filter(col("op") == "u") \
        .select("after.*") \
        .withColumn("cdc_operation", lit("UPDATE"))
    
    # Handle deletes (op = 'd')
    deletes = df.filter(col("op") == "d") \
        .select("before.*") \
        .withColumn("cdc_operation", lit("DELETE"))
    
    # Apply to target (using Delta Lake MERGE)
    all_changes = inserts.union(updates).union(deletes)
    apply_cdc_to_target(all_changes)

# Start streaming
query = parsed_cdc.writeStream \
    .foreachBatch(process_cdc_event) \
    .option("checkpointLocation", "/checkpoints/cdc") \
    .start()</pre>
                        </div>
                    </div>
                </div>
                <div id="delta" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from delta.tables import DeltaTable
from pyspark.sql.functions import col, lit, when

def apply_cdc_to_delta(spark, cdc_df, target_path, key_columns):
    """
    Apply CDC changes to Delta Lake table.
    Handles INSERT, UPDATE, DELETE operations.
    """
    
    target = DeltaTable.forPath(spark, target_path)
    
    # Build merge condition
    merge_condition = " AND ".join([
        f"target.{c} = source.{c}" for c in key_columns
    ])
    
    # Separate operations
    inserts = cdc_df.filter(col("cdc_operation") == "INSERT")
    updates = cdc_df.filter(col("cdc_operation") == "UPDATE")
    deletes = cdc_df.filter(col("cdc_operation") == "DELETE")
    
    # Apply updates and inserts with MERGE
    upserts = inserts.union(updates)
    
    target.alias("target").merge(
        upserts.alias("source"),
        merge_condition
    ).whenMatchedUpdateAll() \
     .whenNotMatchedInsertAll() \
     .execute()
    
    # Apply deletes
    if deletes.count() > 0:
        delete_condition = " OR ".join([
            f"({' AND '.join([f'{c} = {row[c]}' for c in key_columns])})"
            for row in deletes.collect()
        ])
        target.delete(delete_condition)

# Delta Lake Change Data Feed (CDF)
# Enable CDF on table
spark.sql("""
    ALTER TABLE delta.`/path/to/table`
    SET TBLPROPERTIES (delta.enableChangeDataFeed = true)
""")

# Read changes from Delta table
changes = spark.read.format("delta") \
    .option("readChangeFeed", "true") \
    .option("startingVersion", 0) \
    .load("/path/to/table")

# Changes include _change_type column: insert, update_preimage, update_postimage, delete
changes.filter(col("_change_type") == "update_postimage").show()</pre>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>
    <script src="../../assets/js/main.js"></script>
    <script src="../../assets/js/visualization.js"></script>
    <script>
        let viz;
        document.addEventListener('DOMContentLoaded', function() {
            viz = new DataVisualization('visualization', { cameraPosition: { x: 5, y: 3, z: 5 } });
            showCDCFlow();
        });
        function showCDCFlow() {
            viz.clear();
            // Source DB
            viz.createDataNode({ type: 'cylinder', size: 0.5, color: 0x4dabf7, position: { x: -2.5, y: 0.5, z: 0 } });
            viz.createLabel('Source DB', { x: -2.5, y: 1.3, z: 0 });
            // CDC (Debezium)
            viz.createDataNode({ type: 'cube', size: 0.4, color: 0xe25a1c, position: { x: -0.8, y: 0.5, z: 0 } });
            viz.createLabel('CDC', { x: -0.8, y: 1.2, z: 0 });
            // Kafka
            viz.createDataNode({ type: 'cube', size: 0.4, color: 0x8b5cf6, position: { x: 0.8, y: 0.5, z: 0 } });
            viz.createLabel('Kafka', { x: 0.8, y: 1.2, z: 0 });
            // Target DW
            viz.createDataNode({ type: 'cylinder', size: 0.5, color: 0x198754, position: { x: 2.5, y: 0.5, z: 0 } });
            viz.createLabel('Target DW', { x: 2.5, y: 1.3, z: 0 });
            // Arrows
            viz.createArrow({ x: -1.8, y: 0.5, z: 0 }, { x: -1.2, y: 0.5, z: 0 }, { color: 0x888888 });
            viz.createArrow({ x: -0.3, y: 0.5, z: 0 }, { x: 0.3, y: 0.5, z: 0 }, { color: 0x888888 });
            viz.createArrow({ x: 1.3, y: 0.5, z: 0 }, { x: 1.8, y: 0.5, z: 0 }, { color: 0x888888 });
            viz.createLabel('CDC Pipeline: DB -> Debezium -> Kafka -> DW', { x: 0, y: -1.5, z: 0 });
            viz.createGrid(10, 10);
        }
        function showCDCTypes() {
            viz.clear();
            const ops = [
                { name: 'INSERT', color: 0x198754 },
                { name: 'UPDATE', color: 0xffc107 },
                { name: 'DELETE', color: 0xe25a1c }
            ];
            ops.forEach((o, i) => {
                viz.createDataNode({ type: 'cube', size: 0.5, color: o.color, position: { x: -1.2 + i * 1.2, y: 0.5, z: 0 } });
                viz.createLabel(o.name, { x: -1.2 + i * 1.2, y: 1.3, z: 0 });
            });
            viz.createLabel('CDC Operation Types', { x: 0, y: -1.5, z: 0 });
            viz.createGrid(10, 10);
        }
    </script>
</body>
</html>
