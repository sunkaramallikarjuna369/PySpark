<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Window Functions - SQL Learning Hub</title>
    <link rel="stylesheet" href="../../assets/css/main.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <header class="header">
        <div class="container header-content">
            <a href="../../index.html" class="logo"><span>Data Engineering Hub</span></a>
            <nav class="nav"><a href="../../index.html#sql" class="nav-link active">SQL</a><button class="theme-toggle">ðŸŒ™</button></nav>
        </div>
    </header>
    <main class="container">
        <section class="section">
            <h1>Window Functions</h1>
            <p>Window functions perform calculations across a set of rows related to the current row. Learn window functions using standard SQL, PySpark DataFrame API, and PySpark SQL.</p>
            <div id="visualization" class="visualization-container"></div>
            <div class="visualization-controls">
                <button class="viz-btn" onclick="showWindow()">Window</button>
                <button class="viz-btn" onclick="showRanking()">Ranking</button>
            </div>
            <h2>Code Examples</h2>
            <div class="tabs">
                <button class="tab active" data-tab="sql">Standard SQL</button>
                <button class="tab" data-tab="pyspark-df">PySpark DataFrame</button>
                <button class="tab" data-tab="pyspark-sql">PySpark SQL</button>
                <button class="tab" data-tab="comparison">Side-by-Side</button>
            </div>
            <div class="tab-contents">
                <div id="sql" class="tab-content active">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">SQL</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>-- ROW_NUMBER, RANK, DENSE_RANK
SELECT first_name, salary,
    ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num,
    RANK() OVER (ORDER BY salary DESC) AS rank,
    DENSE_RANK() OVER (ORDER BY salary DESC) AS dense_rank
FROM employees;

-- Partition by department
SELECT first_name, salary, department_id,
    ROW_NUMBER() OVER (PARTITION BY department_id ORDER BY salary DESC) AS dept_rank
FROM employees;

-- Running total and average
SELECT first_name, salary,
    SUM(salary) OVER (ORDER BY hire_date) AS running_total,
    AVG(salary) OVER (ORDER BY hire_date) AS running_avg
FROM employees;

-- LAG and LEAD
SELECT first_name, salary,
    LAG(salary) OVER (ORDER BY hire_date) AS prev_salary,
    LEAD(salary) OVER (ORDER BY hire_date) AS next_salary
FROM employees;</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-df" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark DataFrame API)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession
from pyspark.sql.window import Window
from pyspark.sql.functions import col, row_number, rank, dense_rank, ntile
from pyspark.sql.functions import sum, avg, count, lag, lead, first, last

spark = SparkSession.builder.appName("WindowFunctions").getOrCreate()

# Create sample DataFrame
data = [
    (1, "Alice", 50000, 10, "2020-01-15"),
    (2, "Bob", 60000, 10, "2019-03-20"),
    (3, "Charlie", 75000, 20, "2021-06-10"),
    (4, "Diana", 55000, 20, "2018-09-05")
]
df = spark.createDataFrame(data, ["id", "name", "salary", "dept_id", "hire_date"])

# Define window specifications
window_salary = Window.orderBy(col("salary").desc())
window_dept = Window.partitionBy("dept_id").orderBy(col("salary").desc())
window_date = Window.orderBy("hire_date")

# ROW_NUMBER, RANK, DENSE_RANK
df.select("name", "salary",
    row_number().over(window_salary).alias("row_num"),
    rank().over(window_salary).alias("rank"),
    dense_rank().over(window_salary).alias("dense_rank")
).show()

# Partition by department
df.select("name", "salary", "dept_id",
    row_number().over(window_dept).alias("dept_rank")
).show()

# Running total and average
df.select("name", "salary",
    sum("salary").over(window_date).alias("running_total"),
    avg("salary").over(window_date).alias("running_avg")
).show()

# LAG and LEAD
df.select("name", "salary",
    lag("salary", 1).over(window_date).alias("prev_salary"),
    lead("salary", 1).over(window_date).alias("next_salary")
).show()

# NTILE (quartiles)
df.select("name", "salary",
    ntile(4).over(window_salary).alias("quartile")
).show()

# Window frame specification
window_frame = Window.orderBy("hire_date").rowsBetween(-2, 0)
df.select("name", "salary",
    avg("salary").over(window_frame).alias("moving_avg_3")
).show()</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-sql" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark SQL)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("WindowFunctions").getOrCreate()

# Create and register temp view
data = [
    (1, "Alice", 50000, 10, "2020-01-15"),
    (2, "Bob", 60000, 10, "2019-03-20"),
    (3, "Charlie", 75000, 20, "2021-06-10"),
    (4, "Diana", 55000, 20, "2018-09-05")
]
df = spark.createDataFrame(data, ["id", "name", "salary", "dept_id", "hire_date"])
df.createOrReplaceTempView("employees")

# ROW_NUMBER, RANK, DENSE_RANK
spark.sql("""
    SELECT name, salary,
        ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num,
        RANK() OVER (ORDER BY salary DESC) AS rank,
        DENSE_RANK() OVER (ORDER BY salary DESC) AS dense_rank
    FROM employees
""").show()

# Partition by department
spark.sql("""
    SELECT name, salary, dept_id,
        ROW_NUMBER() OVER (PARTITION BY dept_id ORDER BY salary DESC) AS dept_rank
    FROM employees
""").show()

# Running total and average
spark.sql("""
    SELECT name, salary,
        SUM(salary) OVER (ORDER BY hire_date) AS running_total,
        AVG(salary) OVER (ORDER BY hire_date) AS running_avg
    FROM employees
""").show()

# LAG and LEAD
spark.sql("""
    SELECT name, salary,
        LAG(salary) OVER (ORDER BY hire_date) AS prev_salary,
        LEAD(salary) OVER (ORDER BY hire_date) AS next_salary
    FROM employees
""").show()

# NTILE
spark.sql("""
    SELECT name, salary, NTILE(4) OVER (ORDER BY salary DESC) AS quartile
    FROM employees
""").show()</pre>
                        </div>
                    </div>
                </div>
                <div id="comparison" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Side-by-Side Comparison</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre># ============================================
# WINDOW FUNCTIONS: DataFrame API vs SQL
# ============================================
from pyspark.sql import SparkSession
from pyspark.sql.window import Window
from pyspark.sql.functions import col, row_number, rank, sum, lag

spark = SparkSession.builder.appName("Comparison").getOrCreate()

data = [(1, "Alice", 50000, 10), (2, "Bob", 60000, 10), (3, "Charlie", 75000, 20)]
df = spark.createDataFrame(data, ["id", "name", "salary", "dept_id"])
df.createOrReplaceTempView("employees")

# ROW_NUMBER
# DataFrame API:
window = Window.orderBy(col("salary").desc())
df.select("name", "salary", row_number().over(window).alias("row_num")).show()
# PySpark SQL:
spark.sql("SELECT name, salary, ROW_NUMBER() OVER (ORDER BY salary DESC) AS row_num FROM employees").show()

# RANK with PARTITION
# DataFrame API:
window_dept = Window.partitionBy("dept_id").orderBy(col("salary").desc())
df.select("name", "salary", "dept_id", rank().over(window_dept).alias("dept_rank")).show()
# PySpark SQL:
spark.sql("SELECT name, salary, dept_id, RANK() OVER (PARTITION BY dept_id ORDER BY salary DESC) AS dept_rank FROM employees").show()

# RUNNING TOTAL
# DataFrame API:
window_running = Window.orderBy("id")
df.select("name", "salary", sum("salary").over(window_running).alias("running_total")).show()
# PySpark SQL:
spark.sql("SELECT name, salary, SUM(salary) OVER (ORDER BY id) AS running_total FROM employees").show()

# LAG
# DataFrame API:
df.select("name", "salary", lag("salary", 1).over(window).alias("prev_salary")).show()
# PySpark SQL:
spark.sql("SELECT name, salary, LAG(salary) OVER (ORDER BY salary DESC) AS prev_salary FROM employees").show()</pre>
                        </div>
                    </div>
                </div>
            </div>
            <div style="display: flex; justify-content: space-between; margin-top: 3rem; padding-top: 2rem; border-top: 1px solid var(--border-color);">
                <a href="../08_ctes/index.html" style="color: var(--text-muted);">&larr; Previous: CTEs</a>
                <a href="../10_union_set_ops/index.html" style="color: var(--accent-primary);">Next: UNION & Set Operations &rarr;</a>
            </div>
        </section>
    </main>
    <script src="../../assets/js/main.js"></script>
    <script src="../../assets/js/visualization.js"></script>
    <script>
        let viz;
        document.addEventListener('DOMContentLoaded', function() {
            viz = new DataVisualization('visualization', { cameraPosition: { x: 5, y: 3, z: 5 } });
            showWindow();
        });
        function showWindow() {
            viz.clear();
            for (let i = 0; i < 5; i++) {
                const inWindow = i >= 1 && i <= 3;
                viz.createDataNode({ type: 'cube', size: 0.4, color: inWindow ? 0xe25a1c : 0x4dabf7, position: { x: 0, y: 2 - i * 0.7, z: 0 } });
            }
            viz.createLabel('Window Frame', { x: 1.5, y: 0.5, z: 0 });
            viz.createLabel('Window - Sliding frame over rows', { x: 0, y: -2, z: 0 });
            viz.createGrid(10, 10);
        }
        function showRanking() {
            viz.clear();
            const ranks = [1, 2, 2, 4, 5];
            for (let i = 0; i < 5; i++) {
                viz.createDataNode({ type: 'cube', size: 0.4, color: 0x4dabf7, position: { x: 0, y: 2 - i * 0.7, z: 0 } });
                viz.createLabel(String(ranks[i]), { x: 0.8, y: 2 - i * 0.7, z: 0 });
            }
            viz.createLabel('RANK() - Ranking with ties', { x: 0, y: -2, z: 0 });
            viz.createGrid(10, 10);
        }
    </script>
</body>
</html>
