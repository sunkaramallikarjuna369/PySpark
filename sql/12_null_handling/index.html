<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NULL Handling - SQL Learning Hub</title>
    <link rel="stylesheet" href="../../assets/css/main.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <header class="header">
        <div class="container header-content">
            <a href="../../index.html" class="logo"><span>Data Engineering Hub</span></a>
            <nav class="nav"><a href="../../index.html#sql" class="nav-link active">SQL</a><button class="theme-toggle">ðŸŒ™</button></nav>
        </div>
    </header>
    <main class="container">
        <section class="section">
            <h1>NULL Handling</h1>
            <p>NULL represents missing or unknown data. Learn NULL handling using standard SQL, PySpark DataFrame API, and PySpark SQL.</p>
            <div id="visualization" class="visualization-container"></div>
            <div class="visualization-controls">
                <button class="viz-btn" onclick="showNull()">NULL Logic</button>
            </div>
            <h2>Code Examples</h2>
            <div class="tabs">
                <button class="tab active" data-tab="sql">Standard SQL</button>
                <button class="tab" data-tab="pyspark-df">PySpark DataFrame</button>
                <button class="tab" data-tab="pyspark-sql">PySpark SQL</button>
                <button class="tab" data-tab="comparison">Side-by-Side</button>
            </div>
            <div class="tab-contents">
                <div id="sql" class="tab-content active">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">SQL</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>-- Check for NULL
SELECT * FROM employees WHERE manager_id IS NULL;
SELECT * FROM employees WHERE manager_id IS NOT NULL;

-- COALESCE - First non-null value
SELECT COALESCE(commission, 0) AS commission FROM employees;

-- NULLIF - Returns NULL if equal
SELECT NULLIF(value, 0) AS value;

-- NULL in aggregates (NULLs are ignored)
SELECT COUNT(*) FROM employees;  -- Counts all rows
SELECT COUNT(commission) FROM employees;  -- Counts non-NULL only

-- NULLS FIRST / NULLS LAST in ORDER BY
SELECT * FROM employees ORDER BY commission NULLS FIRST;</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-df" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark DataFrame API)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession
from pyspark.sql.functions import col, coalesce, lit, when, isnull, isnan
from pyspark.sql.functions import count, sum, avg, asc_nulls_first, desc_nulls_last

spark = SparkSession.builder.appName("NullHandling").getOrCreate()

# Create sample DataFrame with NULLs
data = [
    (1, "Alice", 50000, 500), (2, "Bob", 60000, None),
    (3, "Charlie", 75000, 1000), (4, "Diana", None, None)
]
df = spark.createDataFrame(data, ["id", "name", "salary", "commission"])

# Check for NULL - isNull() and isNotNull()
df.filter(col("commission").isNull()).show()
df.filter(col("commission").isNotNull()).show()

# Alternative: using isnull() function
df.filter(isnull(col("commission"))).show()

# COALESCE - First non-null value
df.select("name", coalesce(col("commission"), lit(0)).alias("commission")).show()

# Multiple columns in coalesce
df.select("name", coalesce(col("commission"), col("salary"), lit(0)).alias("value")).show()

# NULLIF equivalent using when()
df.select("name", 
    when(col("commission") == 0, None).otherwise(col("commission")).alias("commission")
).show()

# Fill NULL values
df.fillna(0).show()  # Fill all numeric NULLs with 0
df.fillna({"commission": 0, "salary": 50000}).show()  # Column-specific

# Drop rows with NULL
df.dropna().show()  # Drop rows with any NULL
df.dropna(subset=["salary"]).show()  # Drop only if salary is NULL
df.dropna(how="all").show()  # Drop only if all columns are NULL

# NULL in aggregates (NULLs are ignored)
df.agg(count("*"), count("commission"), avg("commission")).show()

# NULLS FIRST / NULLS LAST
df.orderBy(asc_nulls_first("commission")).show()
df.orderBy(desc_nulls_last("commission")).show()
df.orderBy(col("commission").asc_nulls_first()).show()</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-sql" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark SQL)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("NullHandling").getOrCreate()

# Create and register temp view
data = [
    (1, "Alice", 50000, 500), (2, "Bob", 60000, None),
    (3, "Charlie", 75000, 1000), (4, "Diana", None, None)
]
df = spark.createDataFrame(data, ["id", "name", "salary", "commission"])
df.createOrReplaceTempView("employees")

# Check for NULL
spark.sql("SELECT * FROM employees WHERE commission IS NULL").show()
spark.sql("SELECT * FROM employees WHERE commission IS NOT NULL").show()

# COALESCE
spark.sql("SELECT name, COALESCE(commission, 0) AS commission FROM employees").show()

# Multiple columns in COALESCE
spark.sql("SELECT name, COALESCE(commission, salary, 0) AS value FROM employees").show()

# NULLIF
spark.sql("SELECT name, NULLIF(commission, 0) AS commission FROM employees").show()

# IFNULL (alias for COALESCE with 2 args)
spark.sql("SELECT name, IFNULL(commission, 0) AS commission FROM employees").show()

# NVL (same as COALESCE)
spark.sql("SELECT name, NVL(commission, 0) AS commission FROM employees").show()

# NULL in aggregates
spark.sql("""
    SELECT COUNT(*) AS total_rows,
           COUNT(commission) AS non_null_commission,
           AVG(commission) AS avg_commission
    FROM employees
""").show()

# NULLS FIRST / NULLS LAST
spark.sql("SELECT * FROM employees ORDER BY commission NULLS FIRST").show()
spark.sql("SELECT * FROM employees ORDER BY commission DESC NULLS LAST").show()</pre>
                        </div>
                    </div>
                </div>
                <div id="comparison" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Side-by-Side Comparison</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre># ============================================
# NULL HANDLING: DataFrame API vs SQL
# ============================================
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, coalesce, lit, isnull

spark = SparkSession.builder.appName("Comparison").getOrCreate()

data = [(1, "Alice", 500), (2, "Bob", None), (3, "Charlie", 1000)]
df = spark.createDataFrame(data, ["id", "name", "commission"])
df.createOrReplaceTempView("employees")

# IS NULL
# DataFrame API:
df.filter(col("commission").isNull()).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE commission IS NULL").show()

# IS NOT NULL
# DataFrame API:
df.filter(col("commission").isNotNull()).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE commission IS NOT NULL").show()

# COALESCE
# DataFrame API:
df.select("name", coalesce(col("commission"), lit(0)).alias("commission")).show()
# PySpark SQL:
spark.sql("SELECT name, COALESCE(commission, 0) AS commission FROM employees").show()

# FILL NULL
# DataFrame API:
df.fillna(0).show()
# PySpark SQL (no direct equivalent, use COALESCE in SELECT):
spark.sql("SELECT id, name, COALESCE(commission, 0) AS commission FROM employees").show()</pre>
                        </div>
                    </div>
                </div>
            </div>
            <div style="display: flex; justify-content: space-between; margin-top: 3rem; padding-top: 2rem; border-top: 1px solid var(--border-color);">
                <a href="../11_case_statements/index.html" style="color: var(--text-muted);">&larr; Previous: CASE Statements</a>
                <a href="../13_indexes_performance/index.html" style="color: var(--accent-primary);">Next: Indexes & Performance &rarr;</a>
            </div>
        </section>
    </main>
    <script src="../../assets/js/main.js"></script>
    <script src="../../assets/js/visualization.js"></script>
    <script>
        let viz;
        document.addEventListener('DOMContentLoaded', function() {
            viz = new DataVisualization('visualization', { cameraPosition: { x: 5, y: 3, z: 5 } });
            showNull();
        });
        function showNull() {
            viz.clear();
            viz.createDataNode({ type: 'cube', size: 0.5, color: 0x4dabf7, position: { x: -1, y: 0.5, z: 0 } });
            viz.createDataNode({ type: 'cube', size: 0.5, color: 0x333333, position: { x: 0, y: 0.5, z: 0 } });
            viz.createDataNode({ type: 'cube', size: 0.5, color: 0xe25a1c, position: { x: 1, y: 0.5, z: 0 } });
            viz.createLabel('Value', { x: -1, y: 1.2, z: 0 });
            viz.createLabel('NULL', { x: 0, y: 1.2, z: 0 });
            viz.createLabel('Value', { x: 1, y: 1.2, z: 0 });
            viz.createLabel('NULL - Unknown/Missing value', { x: 0, y: -1.5, z: 0 });
            viz.createGrid(10, 10);
        }
    </script>
</body>
</html>
