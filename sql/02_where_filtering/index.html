<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WHERE & Filtering - SQL Learning Hub</title>
    <link rel="stylesheet" href="../../assets/css/main.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <header class="header">
        <div class="container header-content">
            <a href="../../index.html" class="logo"><span>Data Engineering Hub</span></a>
            <nav class="nav"><a href="../../index.html#sql" class="nav-link active">SQL</a><button class="theme-toggle">ðŸŒ™</button></nav>
        </div>
    </header>
    <main class="container">
        <section class="section">
            <h1>WHERE & Filtering</h1>
            <p>The WHERE clause filters rows based on specified conditions. Learn filtering using standard SQL, PySpark DataFrame API, and PySpark SQL.</p>
            <div id="visualization" class="visualization-container"></div>
            <div class="visualization-controls">
                <button class="viz-btn" onclick="showFilter()">Filter</button>
                <button class="viz-btn" onclick="showAnd()">AND</button>
                <button class="viz-btn" onclick="showOr()">OR</button>
            </div>
            <h2>Code Examples</h2>
            <div class="tabs">
                <button class="tab active" data-tab="sql">Standard SQL</button>
                <button class="tab" data-tab="pyspark-df">PySpark DataFrame</button>
                <button class="tab" data-tab="pyspark-sql">PySpark SQL</button>
                <button class="tab" data-tab="comparison">Side-by-Side</button>
            </div>
            <div class="tab-contents">
                <div id="sql" class="tab-content active">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">SQL</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>-- Equality
SELECT * FROM employees WHERE department_id = 10;

-- Not equal
SELECT * FROM employees WHERE department_id != 10;

-- Greater/Less than
SELECT * FROM employees WHERE salary > 50000;
SELECT * FROM employees WHERE salary >= 50000;

-- BETWEEN (inclusive)
SELECT * FROM employees WHERE salary BETWEEN 40000 AND 60000;

-- IN (multiple values)
SELECT * FROM employees WHERE department_id IN (10, 20, 30);

-- NULL checks
SELECT * FROM employees WHERE manager_id IS NULL;
SELECT * FROM employees WHERE manager_id IS NOT NULL;

-- AND / OR
SELECT * FROM employees WHERE department_id = 10 AND salary > 50000;
SELECT * FROM employees WHERE department_id = 10 OR department_id = 20;

-- LIKE pattern matching
SELECT * FROM employees WHERE last_name LIKE 'S%';
SELECT * FROM employees WHERE last_name LIKE '%son';</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-df" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark DataFrame API)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession
from pyspark.sql.functions import col

spark = SparkSession.builder.appName("WhereFiltering").getOrCreate()

# Create sample DataFrame
data = [
    (1, "Alice", "Smith", 50000, 10, 100),
    (2, "Bob", "Johnson", 60000, 20, 100),
    (3, "Charlie", "Brown", 75000, 10, None),
    (4, "Diana", "Prince", 55000, 30, 101)
]
df = spark.createDataFrame(data, ["id", "first_name", "last_name", "salary", "dept_id", "manager_id"])

# Equality
df.filter(col("dept_id") == 10).show()
df.where(col("dept_id") == 10).show()  # where() is alias for filter()

# Not equal
df.filter(col("dept_id") != 10).show()

# Greater/Less than
df.filter(col("salary") > 50000).show()
df.filter(col("salary") >= 50000).show()

# BETWEEN
df.filter(col("salary").between(40000, 60000)).show()

# IN (multiple values)
df.filter(col("dept_id").isin(10, 20, 30)).show()

# NULL checks
df.filter(col("manager_id").isNull()).show()
df.filter(col("manager_id").isNotNull()).show()

# AND / OR
df.filter((col("dept_id") == 10) & (col("salary") > 50000)).show()
df.filter((col("dept_id") == 10) | (col("dept_id") == 20)).show()

# LIKE pattern matching
df.filter(col("last_name").like("S%")).show()
df.filter(col("last_name").like("%son")).show()
df.filter(col("last_name").contains("mi")).show()
df.filter(col("last_name").startswith("S")).show()
df.filter(col("last_name").endswith("son")).show()</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-sql" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark SQL)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("WhereFiltering").getOrCreate()

# Create DataFrame and register as temp view
data = [
    (1, "Alice", "Smith", 50000, 10, 100),
    (2, "Bob", "Johnson", 60000, 20, 100),
    (3, "Charlie", "Brown", 75000, 10, None),
    (4, "Diana", "Prince", 55000, 30, 101)
]
df = spark.createDataFrame(data, ["id", "first_name", "last_name", "salary", "dept_id", "manager_id"])
df.createOrReplaceTempView("employees")

# Equality
spark.sql("SELECT * FROM employees WHERE dept_id = 10").show()

# Not equal
spark.sql("SELECT * FROM employees WHERE dept_id != 10").show()

# Greater/Less than
spark.sql("SELECT * FROM employees WHERE salary > 50000").show()

# BETWEEN
spark.sql("SELECT * FROM employees WHERE salary BETWEEN 40000 AND 60000").show()

# IN
spark.sql("SELECT * FROM employees WHERE dept_id IN (10, 20, 30)").show()

# NULL checks
spark.sql("SELECT * FROM employees WHERE manager_id IS NULL").show()
spark.sql("SELECT * FROM employees WHERE manager_id IS NOT NULL").show()

# AND / OR
spark.sql("SELECT * FROM employees WHERE dept_id = 10 AND salary > 50000").show()
spark.sql("SELECT * FROM employees WHERE dept_id = 10 OR dept_id = 20").show()

# LIKE pattern matching
spark.sql("SELECT * FROM employees WHERE last_name LIKE 'S%'").show()
spark.sql("SELECT * FROM employees WHERE last_name LIKE '%son'").show()</pre>
                        </div>
                    </div>
                </div>
                <div id="comparison" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Side-by-Side Comparison</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre># ============================================
# WHERE FILTERING: DataFrame API vs SQL
# ============================================
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

spark = SparkSession.builder.appName("Comparison").getOrCreate()

data = [(1, "Alice", 50000, 10), (2, "Bob", 60000, 20), (3, "Charlie", 75000, 10)]
df = spark.createDataFrame(data, ["id", "name", "salary", "dept_id"])
df.createOrReplaceTempView("employees")

# EQUALITY FILTER
# DataFrame API:
df.filter(col("dept_id") == 10).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE dept_id = 10").show()

# GREATER THAN
# DataFrame API:
df.filter(col("salary") > 50000).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE salary > 50000").show()

# BETWEEN
# DataFrame API:
df.filter(col("salary").between(50000, 70000)).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE salary BETWEEN 50000 AND 70000").show()

# IN LIST
# DataFrame API:
df.filter(col("dept_id").isin(10, 20)).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE dept_id IN (10, 20)").show()

# AND CONDITION
# DataFrame API:
df.filter((col("dept_id") == 10) & (col("salary") > 50000)).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE dept_id = 10 AND salary > 50000").show()

# OR CONDITION
# DataFrame API:
df.filter((col("dept_id") == 10) | (col("dept_id") == 20)).show()
# PySpark SQL:
spark.sql("SELECT * FROM employees WHERE dept_id = 10 OR dept_id = 20").show()</pre>
                        </div>
                    </div>
                </div>
            </div>
            <div style="display: flex; justify-content: space-between; margin-top: 3rem; padding-top: 2rem; border-top: 1px solid var(--border-color);">
                <a href="../01_select_basics/index.html" style="color: var(--text-muted);">&larr; Previous: SELECT Basics</a>
                <a href="../03_joins/index.html" style="color: var(--accent-primary);">Next: JOINs &rarr;</a>
            </div>
        </section>
    </main>
    <script src="../../assets/js/main.js"></script>
    <script src="../../assets/js/visualization.js"></script>
    <script>
        let viz;
        document.addEventListener('DOMContentLoaded', function() {
            viz = new DataVisualization('visualization', { cameraPosition: { x: 5, y: 3, z: 5 } });
            showFilter();
        });
        function showFilter() {
            viz.clear();
            for (let i = 0; i < 5; i++) {
                const passes = i % 2 === 0;
                viz.createDataNode({ type: 'cube', size: 0.5, color: passes ? 0x198754 : 0x333333, position: { x: 0, y: 2 - i * 0.8, z: 0 } });
            }
            viz.createLabel('WHERE - Filter rows', { x: 0, y: -2.5, z: 0 });
            viz.createGrid(10, 10);
        }
        function showAnd() {
            viz.clear();
            viz.createDataNode({ type: 'cube', size: 0.6, color: 0x4dabf7, position: { x: -1, y: 0.5, z: 0 } });
            viz.createDataNode({ type: 'cube', size: 0.6, color: 0xe25a1c, position: { x: 1, y: 0.5, z: 0 } });
            viz.createLabel('Condition 1', { x: -1, y: 1.3, z: 0 });
            viz.createLabel('Condition 2', { x: 1, y: 1.3, z: 0 });
            viz.createLabel('AND - Both must be true', { x: 0, y: -1.5, z: 0 });
            viz.createGrid(10, 10);
        }
        function showOr() {
            viz.clear();
            viz.createDataNode({ type: 'cube', size: 0.6, color: 0x4dabf7, position: { x: -1, y: 0.5, z: 0 } });
            viz.createDataNode({ type: 'cube', size: 0.6, color: 0xe25a1c, position: { x: 1, y: 0.5, z: 0 } });
            viz.createLabel('Condition 1', { x: -1, y: 1.3, z: 0 });
            viz.createLabel('Condition 2', { x: 1, y: 1.3, z: 0 });
            viz.createLabel('OR - Either can be true', { x: 0, y: -1.5, z: 0 });
            viz.createGrid(10, 10);
        }
    </script>
</body>
</html>
