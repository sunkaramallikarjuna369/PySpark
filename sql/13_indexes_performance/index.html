<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Indexes & Performance - SQL Learning Hub</title>
    <link rel="stylesheet" href="../../assets/css/main.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body>
    <header class="header">
        <div class="container header-content">
            <a href="../../index.html" class="logo"><span>Data Engineering Hub</span></a>
            <nav class="nav"><a href="../../index.html#sql" class="nav-link active">SQL</a><button class="theme-toggle">ðŸŒ™</button></nav>
        </div>
    </header>
    <main class="container">
        <section class="section">
            <h1>Indexes & Performance</h1>
            <p>Indexes speed up data retrieval. Learn performance optimization using standard SQL concepts and PySpark equivalents.</p>
            <div id="visualization" class="visualization-container"></div>
            <div class="visualization-controls">
                <button class="viz-btn" onclick="showIndex()">B-Tree Index</button>
                <button class="viz-btn" onclick="showScan()">Table Scan</button>
            </div>
            <h2>Code Examples</h2>
            <div class="tabs">
                <button class="tab active" data-tab="sql">Standard SQL</button>
                <button class="tab" data-tab="pyspark-df">PySpark DataFrame</button>
                <button class="tab" data-tab="pyspark-sql">PySpark SQL</button>
                <button class="tab" data-tab="comparison">Side-by-Side</button>
            </div>
            <div class="tab-contents">
                <div id="sql" class="tab-content active">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">SQL</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>-- Create basic index
CREATE INDEX idx_employee_name ON employees(last_name);

-- Create composite index
CREATE INDEX idx_emp_dept_salary ON employees(department_id, salary);

-- EXPLAIN query plan
EXPLAIN SELECT * FROM employees WHERE last_name = 'Smith';
EXPLAIN ANALYZE SELECT * FROM employees WHERE department_id = 10;

-- Index usage tips:
-- 1. Index columns used in WHERE, JOIN, ORDER BY
-- 2. Put most selective column first in composite index
-- 3. Avoid functions on indexed columns in WHERE</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-df" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark DataFrame API)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession
from pyspark.sql.functions import col, broadcast

spark = SparkSession.builder.appName("Performance").getOrCreate()

# Create sample DataFrame
data = [(i, f"Name{i}", i * 1000, i % 10) for i in range(1, 1001)]
df = spark.createDataFrame(data, ["id", "name", "salary", "dept_id"])

# EXPLAIN - View query execution plan
df.filter(col("name") == "Name100").explain()
df.filter(col("name") == "Name100").explain(True)  # Extended plan
df.filter(col("name") == "Name100").explain("formatted")  # Formatted plan

# Performance optimization techniques:

# 1. Partitioning - organize data by column
df.write.partitionBy("dept_id").parquet("/tmp/employees_partitioned")
# Reading partitioned data is faster for filtered queries
spark.read.parquet("/tmp/employees_partitioned").filter(col("dept_id") == 5).explain()

# 2. Bucketing - hash-based distribution
df.write.bucketBy(10, "dept_id").sortBy("salary").saveAsTable("employees_bucketed")

# 3. Caching - keep data in memory
df.cache()  # or df.persist()
df.count()  # Trigger caching
df.filter(col("salary") > 50000).show()  # Uses cached data
df.unpersist()  # Release cache

# 4. Broadcast join - for small tables
small_df = spark.createDataFrame([(1, "IT"), (2, "HR")], ["dept_id", "dept_name"])
df.join(broadcast(small_df), "dept_id").explain()

# 5. Repartition vs Coalesce
df.repartition(10)  # Shuffle to 10 partitions
df.coalesce(2)  # Reduce to 2 partitions (no shuffle)

# 6. Filter pushdown - filter early
df.filter(col("salary") > 50000).select("name", "salary").explain()

# 7. Column pruning - select only needed columns
df.select("name", "salary").explain()</pre>
                        </div>
                    </div>
                </div>
                <div id="pyspark-sql" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Python (PySpark SQL)</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre>from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Performance").getOrCreate()

# Create and register temp view
data = [(i, f"Name{i}", i * 1000, i % 10) for i in range(1, 1001)]
df = spark.createDataFrame(data, ["id", "name", "salary", "dept_id"])
df.createOrReplaceTempView("employees")

# EXPLAIN query plan
spark.sql("EXPLAIN SELECT * FROM employees WHERE name = 'Name100'").show(truncate=False)
spark.sql("EXPLAIN EXTENDED SELECT * FROM employees WHERE dept_id = 5").show(truncate=False)

# Performance optimization with SQL:

# 1. Cache table
spark.sql("CACHE TABLE employees")
spark.sql("SELECT * FROM employees WHERE salary > 50000").show()
spark.sql("UNCACHE TABLE employees")

# 2. Broadcast hint for joins
small_df = spark.createDataFrame([(1, "IT"), (2, "HR")], ["dept_id", "dept_name"])
small_df.createOrReplaceTempView("departments")

spark.sql("""
    SELECT /*+ BROADCAST(departments) */ e.*, d.dept_name
    FROM employees e
    JOIN departments d ON e.dept_id = d.dept_id
""").explain()

# 3. Repartition hint
spark.sql("""
    SELECT /*+ REPARTITION(10) */ * FROM employees
""").explain()

# 4. Coalesce hint
spark.sql("""
    SELECT /*+ COALESCE(2) */ * FROM employees
""").explain()

# 5. Analyze table for statistics
spark.sql("ANALYZE TABLE employees COMPUTE STATISTICS")
spark.sql("ANALYZE TABLE employees COMPUTE STATISTICS FOR COLUMNS salary, dept_id")

# 6. Describe table
spark.sql("DESCRIBE EXTENDED employees").show(truncate=False)</pre>
                        </div>
                    </div>
                </div>
                <div id="comparison" class="tab-content">
                    <div class="code-container">
                        <div class="code-header"><span class="code-language">Side-by-Side Comparison</span><button class="copy-btn">Copy</button></div>
                        <div class="code-block">
<pre># ============================================
# PERFORMANCE: DataFrame API vs SQL
# ============================================
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, broadcast

spark = SparkSession.builder.appName("Comparison").getOrCreate()

data = [(i, f"Name{i}", i * 1000) for i in range(1, 101)]
df = spark.createDataFrame(data, ["id", "name", "salary"])
df.createOrReplaceTempView("employees")

# EXPLAIN
# DataFrame API:
df.filter(col("salary") > 50000).explain()
# PySpark SQL:
spark.sql("EXPLAIN SELECT * FROM employees WHERE salary > 50000").show(truncate=False)

# CACHE
# DataFrame API:
df.cache()
# PySpark SQL:
spark.sql("CACHE TABLE employees")

# BROADCAST JOIN
small = spark.createDataFrame([(1, "A")], ["id", "val"])
small.createOrReplaceTempView("small_table")
# DataFrame API:
df.join(broadcast(small), "id").explain()
# PySpark SQL:
spark.sql("SELECT /*+ BROADCAST(small_table) */ * FROM employees e JOIN small_table s ON e.id = s.id").explain()

# Note: PySpark doesn't use traditional indexes like databases
# Instead, it uses partitioning, bucketing, and caching for optimization</pre>
                        </div>
                    </div>
                </div>
            </div>
            <div style="display: flex; justify-content: space-between; margin-top: 3rem; padding-top: 2rem; border-top: 1px solid var(--border-color);">
                <a href="../12_null_handling/index.html" style="color: var(--text-muted);">&larr; Previous: NULL Handling</a>
                <a href="../14_views/index.html" style="color: var(--accent-primary);">Next: Views &rarr;</a>
            </div>
        </section>
    </main>
    <script src="../../assets/js/main.js"></script>
    <script src="../../assets/js/visualization.js"></script>
    <script>
        let viz;
        document.addEventListener('DOMContentLoaded', function() {
            viz = new DataVisualization('visualization', { cameraPosition: { x: 5, y: 3, z: 5 } });
            showIndex();
        });
        function showIndex() {
            viz.clear();
            // B-Tree structure
            viz.createDataNode({ type: 'sphere', size: 0.4, color: 0xe25a1c, position: { x: 0, y: 1.5, z: 0 } });
            viz.createDataNode({ type: 'sphere', size: 0.3, color: 0x4dabf7, position: { x: -1, y: 0.5, z: 0 } });
            viz.createDataNode({ type: 'sphere', size: 0.3, color: 0x4dabf7, position: { x: 1, y: 0.5, z: 0 } });
            viz.createDataNode({ type: 'sphere', size: 0.25, color: 0x198754, position: { x: -1.5, y: -0.3, z: 0 } });
            viz.createDataNode({ type: 'sphere', size: 0.25, color: 0x198754, position: { x: -0.5, y: -0.3, z: 0 } });
            viz.createDataNode({ type: 'sphere', size: 0.25, color: 0x198754, position: { x: 0.5, y: -0.3, z: 0 } });
            viz.createDataNode({ type: 'sphere', size: 0.25, color: 0x198754, position: { x: 1.5, y: -0.3, z: 0 } });
            viz.createLabel('B-Tree Index - O(log n) lookup', { x: 0, y: -1.5, z: 0 });
            viz.createGrid(10, 10);
        }
        function showScan() {
            viz.clear();
            for (let i = 0; i < 8; i++) {
                viz.createDataNode({ type: 'cube', size: 0.3, color: i === 5 ? 0xe25a1c : 0x4dabf7, position: { x: -2.5 + i * 0.7, y: 0.5, z: 0 } });
            }
            viz.createLabel('Table Scan - O(n) lookup', { x: 0, y: -1.5, z: 0 });
            viz.createGrid(10, 10);
        }
    </script>
</body>
</html>
